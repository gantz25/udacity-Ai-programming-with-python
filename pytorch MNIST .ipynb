{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f9b9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbbf8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function\n",
    "    \n",
    "    ARGS:\n",
    "    \n",
    "    x: torch.Tensor\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bf6c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting manual seed to a predicatble things\n",
    "torch.manual_seed(7)\n",
    "features=torch.randn((1,5)) #creating tensor of 1 row and 6 columns that contains values randomly disturbuted \n",
    "#according to a normal disturbtuion with mean 0 and std of 1\n",
    "weights=torch.randn_like(features)\n",
    "bias=torch.randn((1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ca3149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=activation((weights.view(5,1)*features).sum()+bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44d36d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1034]])\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68e231c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi neural network \n",
    "torch.manual_seed(7)\n",
    "features=torch.randn((1,3))\n",
    "n_input=features.shape[1]\n",
    "n_hidden=2\n",
    "n_output=1\n",
    "\n",
    "w1=torch.randn(n_input,n_hidden)\n",
    "w2=torch.randn(n_hidden,n_output)\n",
    "\n",
    "b1=torch.randn((1,n_hidden))\n",
    "b2=torch.randn((1,n_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a2e58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden=activation(torch.sum(torch.matmul(w1.view(2,3),features.view(3,1)))+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d2e3dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe43c26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8733, 0.8738]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dc76ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=activation(torch.sum(torch.matmul(w2,hidden))+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26fa8488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1050]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5912ef4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.arange(0,4)\n",
    "b=torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "815fe9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d32db",
   "metadata": {},
   "source": [
    "# building neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7f57921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6526074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing mnist data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbd7b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a990304c7374825a74ed2aef71b4691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohamed/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee50eb879874bccad95ed2d2ff1b5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohamed/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e57b5468ab42f7a96b014eb7cc580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohamed/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef68feed0ea9457a8f2edaeb3e8d70d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mohamed/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/mohamed/.pytorch/MNIST_data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d04b9269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a4e1748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e424c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=images.view(images.shape[0],-1)# choosing -1 for it to choose the most appropiate number\n",
    "w1=torch.randn(784,256)\n",
    "b1=torch.randn(256)\n",
    "w2=torch.randn(256,10)\n",
    "b2=torch.randn(10)\n",
    "h=activation(torch.mm(inputs,w1)+b1)\n",
    "out=torch.mm(h,w2)+b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02a7b354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "701941de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "37ab9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8708cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # inputs to a hidden layer linear transformation \n",
    "        self.hidden=nn.Linear(784,256)\n",
    "        self.output=nn.Linear(256,10)\n",
    "        \n",
    "        # define sigmoid activation and softmax output\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8472c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myown neural network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1=nn.Linear(784,128)\n",
    "        self.hidden2=nn.Linear(128,64)\n",
    "        self.output=nn.Linear(64,10)\n",
    "    def forward(self,x):\n",
    "        x=self.hidden1(x)\n",
    "        x= nn.Module.relu(x)\n",
    "        x=self.hidden2(x)\n",
    "        x=nn.Module.relu(x)\n",
    "        x=self.output(x)\n",
    "        x=nn.Module.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcccc3c",
   "metadata": {},
   "source": [
    "## losses in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a1fa124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.CrossEntropyLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bc65287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3382, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# buidling a model\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bb8b23c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3248, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa23ca",
   "metadata": {},
   "source": [
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, autograd, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set requires_grad = True on a tensor. You can do this at creation with the requires_grad keyword, or at any time with x.requires_grad_(True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "115e3fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d53122f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backward pass: \n",
      " tensor([[ 0.0020,  0.0020,  0.0020,  ...,  0.0020,  0.0020,  0.0020],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [-0.0015, -0.0015, -0.0015,  ..., -0.0015, -0.0015, -0.0015],\n",
      "        [ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d7c4f",
   "metadata": {},
   "source": [
    "here's one last piece we need to start training, an optimizer that we'll use to update the weights with the gradients. We get these from PyTorch's optim package. For example we can use stochastic gradient descent with optim.SGD. You can see how to define an optimizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd6675bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0154,  0.0078,  0.0194,  ..., -0.0062,  0.0331, -0.0176],\n",
      "        [-0.0309, -0.0265, -0.0343,  ..., -0.0351,  0.0228, -0.0162],\n",
      "        [-0.0010, -0.0314, -0.0307,  ..., -0.0010, -0.0102, -0.0086],\n",
      "        ...,\n",
      "        [ 0.0065, -0.0041,  0.0353,  ...,  0.0312, -0.0262, -0.0034],\n",
      "        [-0.0091,  0.0059,  0.0079,  ..., -0.0331,  0.0308,  0.0298],\n",
      "        [ 0.0355, -0.0084,  0.0252,  ...,  0.0325, -0.0165,  0.0257]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [ 0.0044,  0.0044,  0.0044,  ...,  0.0044,  0.0044,  0.0044],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        [-0.0064, -0.0064, -0.0064,  ..., -0.0064, -0.0064, -0.0064],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016]])\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7357b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0154,  0.0078,  0.0194,  ..., -0.0062,  0.0331, -0.0176],\n",
      "        [-0.0310, -0.0265, -0.0343,  ..., -0.0352,  0.0227, -0.0162],\n",
      "        [-0.0010, -0.0314, -0.0307,  ..., -0.0010, -0.0102, -0.0086],\n",
      "        ...,\n",
      "        [ 0.0066, -0.0041,  0.0354,  ...,  0.0312, -0.0262, -0.0033],\n",
      "        [-0.0091,  0.0059,  0.0079,  ..., -0.0331,  0.0308,  0.0298],\n",
      "        [ 0.0355, -0.0084,  0.0252,  ...,  0.0325, -0.0165,  0.0257]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bce38f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8450131201540738\n",
      "Training loss: 0.8034967780430943\n",
      "Training loss: 0.5252018984891712\n",
      "Training loss: 0.4336673424346869\n",
      "Training loss: 0.3882130520430201\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5cc19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
